{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yatzy - Deep RL - Gen 8.1\n",
    "##### Uses 3 networks as opposed to one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "import random\n",
    "import math\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from player import Player\n",
    "from hand import YatzyHand\n",
    "from deep_rl import create_state, get_indices, check_end, first_turn, check_state_end\n",
    "\n",
    "from ai_gen_8 import AIGenEightPointOne\n",
    "from deeprlgame2 import DeepRLGame3DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MovesTransition = namedtuple('MoveTransition', \n",
    "                            ('state', 'move', 'reward'))\n",
    "RerollTransition = namedtuple('RerollTransition',\n",
    "                            ('state', 'reroll', 'next_state'))\n",
    "IndicesTransition = namedtuple('IndicesTransition', \n",
    "                            ('state', 'indices', 'next_state'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Memories and Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovesReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "    \n",
    "    def push(self, *args):\n",
    "        self.memory.append(MovesTransition(*args))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndicesReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "    \n",
    "    def push(self, *args):\n",
    "        self.memory.append(IndicesTransition(*args))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RerollReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "    \n",
    "    def push(self, *args):\n",
    "        self.memory.append(RerollTransition(*args))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovesDQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.layer1 = nn.Linear(20, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 15)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.softmax(self.layer3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndicesDQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.layer1 = nn.Linear(20, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 31)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.softmax(self.layer3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RerollDQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.layer1 = nn.Linear(20, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.softmax(self.layer3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_action_dicts():\n",
    "    moves = {0: 'ones', 1: 'twos', 2: 'threes', 3: 'fours', 4: 'fives',\n",
    "  5: 'sixes', 6: 'one_pair', 7: 'two_pair', 8: 'three_kind', 9: 'four_kind', 10: 'small_straight',\n",
    "  11: 'large_straight', 12: 'full_house', 13: 'chance', 14: 'yatzy'}\n",
    "\n",
    "    reroll = {0: 'True', 1: 'False'}\n",
    "\n",
    "    indices = {0: (0,), 1: (1,), 2: (2,), 3: (3,), 4: (4,), 5: (0, 1), 6: (0, 2),\n",
    "  7: (0, 3), 8: (0, 4), 9: (1, 2), 10: (1, 3), 11: (1, 4), 12: (2, 3), 13: (2, 4),\n",
    "  14: (3, 4), 15: (0, 1, 2), 16: (0, 1, 3), 17: (0, 1, 4), 18: (0, 2, 3), 19: (0, 2, 4), \n",
    "  20: (0, 3, 4), 21: (1, 2, 3), 22: (1, 2, 4), 23: (1, 3, 4), 24: (2, 3, 4), 25: (0, 1, 2, 3),\n",
    "  26: (0, 1, 2, 4), 27: (0, 1, 3, 4), 28: (0, 2, 3, 4), 29: (1, 2, 3, 4), 30: (0, 1, 2, 3, 4)}\n",
    "\n",
    "    \n",
    "    return moves, reroll, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_moves(scoresheet):\n",
    "    available = {}\n",
    "    for i, (key, value) in enumerate(scoresheet.items()):\n",
    "        if value is not None:\n",
    "            available[i] = False\n",
    "        else:\n",
    "            available[i] = True\n",
    "    return available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_rerolls():\n",
    "    return {0: True, 1: True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_indices():\n",
    "    final = {}\n",
    "    for i in range(1, 6):\n",
    "         for j, comb in enumerate(it.combinations([0, 1, 2, 3, 4], i)):\n",
    "            final[j] = comb\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_move(state, available_moves, episode_num, eps=True):\n",
    "    sample = random.random()\n",
    "    eps_threshold = eps_final + (eps_initial - eps_final) * math.exp(-1.0 * episode_num / eps_decay)\n",
    "\n",
    "    if sample < eps_threshold and eps:\n",
    "        return torch.tensor(random.choice([x for x in available_moves if available_moves[x]])).view(1).to(device)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            results = moves_target(state)\n",
    "            for i in range(15):\n",
    "                if available_moves[i] == False:\n",
    "                    results[i] = 0\n",
    "            return torch.argmax(results).view(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_reroll(state, available_rerolls, episode_num, eps=True):\n",
    "    sample = random.random()\n",
    "    eps_threshold = eps_final + (eps_initial - eps_final) * math.exp(-1.0 * episode_num / eps_decay)\n",
    "\n",
    "    if sample < eps_threshold and eps:\n",
    "        return torch.tensor(random.choice([x for x in available_rerolls if available_rerolls[x]])).view(1).to(device)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            results = reroll_target(state)\n",
    "            return torch.argmax(results).view(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_indices(state, available_indices, episode_num, eps=True):\n",
    "    sample = random.random()\n",
    "    eps_threshold = eps_final + (eps_initial - eps_final) * math.exp(-1.0 * episode_num / eps_decay)\n",
    "\n",
    "    if sample < eps_threshold and eps:\n",
    "        return torch.tensor(random.choice([x for x in available_indices if available_indices[x]])).view(1).to(device)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            results = indices_target(state)\n",
    "            return torch.argmax(results).view(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6823819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_moves():\n",
    "    if len(moves_memory) < bs:\n",
    "        return\n",
    "    transitions = moves_memory.sample(bs)\n",
    "\n",
    "    batch = MovesTransition(*zip(*transitions))\n",
    "\n",
    "    state_batch = torch.stack(batch.state)\n",
    "    action_batch = torch.stack(batch.move)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = moves_policy(state_batch).gather(1, action_batch).squeeze()\n",
    "    \n",
    "    \n",
    "    expected_state_action_values = reward_batch\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values)\n",
    "\n",
    "    moves_opt.zero_grad()\n",
    "    loss.backward()\n",
    "    moves_opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_reroll():\n",
    "    if len(reroll_memory) < bs:\n",
    "        return\n",
    "    transitions = reroll_memory.sample(bs)\n",
    "\n",
    "    batch = RerollTransition(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: not check_state_end(s), batch.next_state)), device=device, dtype = torch.bool)\n",
    "\n",
    "    state_batch = torch.stack(batch.state)\n",
    "    action_batch = torch.stack(batch.reroll)\n",
    "    non_final_next_states = torch.stack([s for s in batch.next_state if not check_state_end(s)])\n",
    "\n",
    "    state_action_values = reroll_policy(state_batch).gather(1, action_batch).squeeze()\n",
    "    \n",
    "    next_state_values = torch.zeros(bs, device=device)\n",
    "    next_state_values[non_final_mask] = reroll_target(non_final_next_states).max(1)[0].detach()\n",
    "\n",
    "    expected_state_action_values = next_state_values \n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values)\n",
    "\n",
    "    reroll_opt.zero_grad()\n",
    "    loss.backward()\n",
    "    reroll_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_indices():\n",
    "    if len(indices_memory) < bs:\n",
    "        return\n",
    "    transitions = indices_memory.sample(bs)\n",
    "\n",
    "    batch = IndicesTransition(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: not check_state_end(s), batch.next_state)), device=device, dtype = torch.bool)\n",
    "\n",
    "    state_batch = torch.stack(batch.state)\n",
    "    action_batch = torch.stack(batch.indices)\n",
    "    non_final_next_states = torch.stack([s for s in batch.next_state if not check_state_end(s)])\n",
    "\n",
    "    state_action_values = indices_policy(state_batch).gather(1, action_batch).squeeze()\n",
    "    \n",
    "    next_state_values = torch.zeros(bs, device=device)\n",
    "    next_state_values[non_final_mask] = indices_target(non_final_next_states).max(1)[0].detach()\n",
    "    \n",
    "    expected_state_action_values = next_state_values\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values)\n",
    "\n",
    "    indices_opt.zero_grad()\n",
    "    loss.backward()\n",
    "    indices_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(num):\n",
    "    # evaluates a model by having it play num games\n",
    "    \n",
    "    player = AIGenEightPointOne('karen')\n",
    "\n",
    "    game = DeepRLGame3DQN(player.generation)\n",
    "\n",
    "    scores = game.evaluate(num)\n",
    "\n",
    "    print('Average score: {}'.format(sum(scores) / len(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_initial = 0.9\n",
    "eps_final = 0.05\n",
    "eps_decay = 100\n",
    "\n",
    "lr = 0.01\n",
    "bs = 64\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "moves_policy = MovesDQN().to(device)\n",
    "moves_target = MovesDQN().to(device)\n",
    "moves_target.load_state_dict(moves_policy.state_dict())\n",
    "moves_target.eval()\n",
    "moves_opt = optim.SGD(moves_policy.parameters(), lr=lr)\n",
    "moves_memory = MovesReplayMemory(10000)\n",
    "\n",
    "reroll_policy = RerollDQN().to(device)\n",
    "reroll_target = RerollDQN().to(device)\n",
    "reroll_target.load_state_dict(reroll_policy.state_dict())\n",
    "reroll_target.eval()\n",
    "reroll_opt = optim.SGD(reroll_policy.parameters(), lr=lr)\n",
    "reroll_memory = RerollReplayMemory(10000)\n",
    "\n",
    "\n",
    "indices_policy = IndicesDQN().to(device)\n",
    "indices_target = IndicesDQN().to(device)\n",
    "indices_target.load_state_dict(indices_policy.state_dict())\n",
    "indices_target.eval()\n",
    "indices_opt = optim.SGD(indices_policy.parameters(), lr=lr)\n",
    "indices_memory = IndicesReplayMemory(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n, gen, num):\n",
    "    moves_dict, reroll_dict, indices_dict = create_action_dicts()\n",
    "\n",
    "    reroll_options = available_rerolls()\n",
    "    indices_options = available_indices()\n",
    "\n",
    "    eps_decay = n / 2\n",
    "\n",
    "    for i in range(n):\n",
    "        player = Player('karen')\n",
    "        scoresheet = player.scoresheet\n",
    "\n",
    "    \n",
    "        while not check_end(scoresheet):\n",
    "            hand = YatzyHand()\n",
    "            state = create_state(scoresheet, hand)\n",
    "\n",
    "            rerolls = 0\n",
    "\n",
    "            reroll_action = select_reroll(state, reroll_options, i)\n",
    "            \n",
    "            while reroll_action == 0:\n",
    "                indices_action = select_indices(state, indices_options, i)\n",
    "                hand = hand.reroll(list(indices_action))\n",
    "                rerolls += 1\n",
    "                new_state = create_state(scoresheet, hand)\n",
    "\n",
    "                reroll_memory.push(state, reroll_action, new_state)\n",
    "                indices_memory.push(state, indices_action, new_state)\n",
    "\n",
    "                reroll_action = select_reroll(new_state, reroll_options, i) if rerolls < 2 else 1\n",
    "                state = new_state\n",
    "            \n",
    "            move_action = select_move(state, available_moves(scoresheet), i)\n",
    "            action_name = moves_dict[move_action.item()]\n",
    "            score = getattr(hand, action_name)()\n",
    "            player.update_scoresheet(action_name, score)\n",
    "\n",
    "            moves_memory.push(state, move_action, torch.tensor([score]))\n",
    "        \n",
    "        \n",
    "        optimize_moves()\n",
    "        optimize_reroll()\n",
    "        optimize_indices()\n",
    "\n",
    "        if i % TARGET_UPDATE == 0:\n",
    "            moves_target.load_state_dict(moves_policy.state_dict())\n",
    "            reroll_target.load_state_dict(reroll_policy.state_dict())\n",
    "            indices_target.load_state_dict(indices_policy.state_dict())\n",
    "        \n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print('Run {} done'.format(i))\n",
    "            torch.save(moves_target.state_dict(), f'dqn_models/{gen}test3/{num}/moves.pt')\n",
    "            torch.save(reroll_target.state_dict(), f'dqn_models/{gen}test3/{num}/reroll.pt')\n",
    "            torch.save(indices_target.state_dict(), f'dqn_models/{gen}test3/{num}/indices.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 done\n",
      "Run 1000 done\n",
      "Run 2000 done\n",
      "Run 3000 done\n",
      "Run 4000 done\n",
      "Run 5000 done\n",
      "Run 6000 done\n",
      "Run 7000 done\n",
      "Run 8000 done\n",
      "Run 9000 done\n",
      "Run 10000 done\n",
      "Run 11000 done\n",
      "Run 12000 done\n",
      "Run 13000 done\n",
      "Run 14000 done\n",
      "Run 15000 done\n",
      "Run 16000 done\n",
      "Run 17000 done\n",
      "Run 18000 done\n",
      "Run 19000 done\n",
      "Run 20000 done\n",
      "Run 21000 done\n",
      "Run 22000 done\n",
      "Run 23000 done\n",
      "Run 24000 done\n",
      "Run 25000 done\n",
      "Run 26000 done\n",
      "Run 27000 done\n",
      "Run 28000 done\n",
      "Run 29000 done\n",
      "Run 30000 done\n",
      "Run 31000 done\n",
      "Run 32000 done\n",
      "Run 33000 done\n",
      "Run 34000 done\n",
      "Run 35000 done\n",
      "Run 36000 done\n",
      "Run 37000 done\n",
      "Run 38000 done\n",
      "Run 39000 done\n",
      "Run 40000 done\n",
      "Run 41000 done\n",
      "Run 42000 done\n",
      "Run 43000 done\n",
      "Run 44000 done\n",
      "Run 45000 done\n",
      "Run 46000 done\n",
      "Run 47000 done\n",
      "Run 48000 done\n",
      "Run 49000 done\n"
     ]
    }
   ],
   "source": [
    "train(50000, '8.1', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2cabb87546583d089e0e7dc4e55b4bf60825fbd1f801f1fd57617645dbbf57f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
