{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d76b3675",
   "metadata": {},
   "source": [
    "# Yatzy - Deep RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952feaf2",
   "metadata": {},
   "source": [
    "## Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bcc36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "5643f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "import random\n",
    "import math\n",
    "import itertools as it\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74fb60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from player import Player\n",
    "from hand import YatzyHand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "111baeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24fa008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec4ef2",
   "metadata": {},
   "source": [
    "## Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5968891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "    \n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a91a16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.layer1 = nn.Linear(20, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 46)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.softmax(self.layer3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeadd69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e5f98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_state():\n",
    "    l = [random.random() for _ in range(15)]\n",
    "    t = sorted([random.randint(1,6) / 6 for _ in range(5)])\n",
    "    return torch.tensor(l + t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d4be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73845f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd270b3a",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "df2c6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eps(n):\n",
    "    values = []\n",
    "    eps_initial = 1\n",
    "    eps_final = 0.05\n",
    "    eps_decay = 5000\n",
    "\n",
    "    for i in range(n):\n",
    "        eps = eps_final + (eps_initial - eps_final) * math.exp(-1.0 * i / eps_decay)\n",
    "\n",
    "        values.append(eps)\n",
    "    plt.ylim([0,1.1])\n",
    "    plt.plot(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43951b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a395e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "921e64a6",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "85d8c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_action_dict():\n",
    "    actions = {}\n",
    "\n",
    "    counter = 0\n",
    "    player = Player('joe')\n",
    "    for action in player.scoresheet.keys():\n",
    "        actions[counter] = action\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    rerolls = []\n",
    "    for i in range(1, 6):   \n",
    "        for combo in it.combinations([0, 1, 2, 3, 4], r=i):\n",
    "            rerolls.append('reroll {}'.format(combo))\n",
    "\n",
    "    for roll in rerolls:\n",
    "        actions[counter] = roll\n",
    "        counter += 1\n",
    "    \n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a09e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(scoresheet, reroll=False):\n",
    "    available = {}\n",
    "    for i, (key, value) in enumerate(scoresheet.items()):\n",
    "        if value is not None:\n",
    "            available[i] = False\n",
    "        else:\n",
    "            available[i] = True\n",
    "    for i in range(15, 46):\n",
    "        available[i] = bool(reroll)\n",
    "    return available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "78987964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, available_actions, episode_num):\n",
    "    # returns a number between 1 and 46 that tells you what action to take\n",
    "    sample = random.random()\n",
    "    eps_threshold = eps_final + (eps_initial - eps_final) * math.exp(-1.0 * episode_num / eps_decay)\n",
    "    if sample < eps_threshold:\n",
    "        return torch.tensor(random.choice([x for x in available_actions if available_actions[x]])).view(1).to(device)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            results = target_net(state)\n",
    "            for i in range(46):\n",
    "                if available_actions[i] == False:\n",
    "                    results[i] = 0\n",
    "            return torch.argmax(results).view(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "3aaf89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state(scoresheet, hand):\n",
    "    s = []\n",
    "    divisors = {\n",
    "                'ones': 5, \n",
    "                'twos': 10, \n",
    "                'threes': 15, \n",
    "                'fours': 20, \n",
    "                'fives': 25, \n",
    "                'sixes': 30, \n",
    "                'one_pair': 12, \n",
    "                'two_pair': 22, \n",
    "                'three_kind': 18, \n",
    "                'four_kind': 24,\n",
    "                'small_straight': 15,\n",
    "                'large_straight': 20, \n",
    "                'full_house': 28, \n",
    "                'chance': 30, \n",
    "                'yatzy': 50\n",
    "            }\n",
    "    for key, value in scoresheet.items():\n",
    "        if not isinstance(value, int):\n",
    "            s.append(-1)\n",
    "        else:\n",
    "            s.append(value / divisors[key])\n",
    "\n",
    "    for die in hand:\n",
    "        s.append(int(die) / 6)\n",
    "\n",
    "    return torch.tensor(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8906c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(action):\n",
    "    numbers = re.findall(f'\\d', action)\n",
    "    return [int(x) for x in numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "059736ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_end(scoresheet):\n",
    "    return all([isinstance(x, int) for x in scoresheet.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a7e7bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_turn(scoresheet):\n",
    "    return True if list(scoresheet.values()).count(None) == len(scoresheet.values()) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "81cea164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_state_end(state):\n",
    "    state = list(state)\n",
    "    return all([x != -1 for x in state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "6823819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < bs:\n",
    "        return\n",
    "    transitions = memory.sample(bs)\n",
    "\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: not check_state_end(s), batch.next_state)), device=device, dtype = torch.bool)\n",
    "\n",
    "    state_batch = torch.stack(batch.state)\n",
    "    action_batch = torch.stack(batch.action)\n",
    "    non_final_next_states = torch.stack([s for s in batch.next_state if not check_state_end(s)])\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch).squeeze()\n",
    "    \n",
    "    next_state_values = torch.zeros(bs, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    \n",
    "    expected_state_action_values = next_state_values + reward_batch\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787faee6",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "067ca792",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "lr = 0.01\n",
    "eps_initial = 1\n",
    "eps_final = 0.05\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "\n",
    "policy_net = DQN().to(device)\n",
    "target_net = DQN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "opt = optim.SGD(policy_net.parameters(), lr=lr)\n",
    "memory = ReplayMemory(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "241ffe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n, name):\n",
    "    action_dict = create_action_dict()\n",
    "\n",
    "    eps_decay = n / 2\n",
    "\n",
    "    for i in range(n):\n",
    "        player = Player('karen')\n",
    "        scoresheet = player.scoresheet\n",
    "\n",
    "        hand = YatzyHand()\n",
    "        state = create_state(scoresheet, hand)\n",
    "        new_state = state\n",
    "\n",
    "        while not check_end(scoresheet):\n",
    "            rerolls = 0\n",
    "            \n",
    "            options = available_actions(scoresheet, reroll=True)\n",
    "\n",
    "            old_state = new_state\n",
    "            action = select_action(old_state, options, i)\n",
    "            \n",
    "\n",
    "            while action >= 15:\n",
    "                action_name = action_dict[action.item()]\n",
    "                indices = get_indices(action_name)\n",
    "                hand = hand.reroll(indices)\n",
    "                rerolls += 1\n",
    "                new_state = create_state(scoresheet, hand)\n",
    "\n",
    "                memory.push(old_state, action, new_state, torch.tensor([0]))\n",
    "\n",
    "                options = available_actions(scoresheet, reroll=True) if rerolls < 2 else available_actions(scoresheet, reroll=False)\n",
    "                action = select_action(new_state, options, i)\n",
    "\n",
    "                old_state = new_state\n",
    "\n",
    "            \n",
    "            action_name = action_dict[action.item()]\n",
    "            score = getattr(hand, action_name)()\n",
    "            player.update_scoresheet(action_name, score)\n",
    "\n",
    "            hand = YatzyHand()\n",
    "\n",
    "            new_state = create_state(scoresheet, hand)\n",
    "\n",
    "            memory.push(old_state, action, new_state, torch.tensor(score).view(1))\n",
    "        \n",
    "        optimize_model()\n",
    "\n",
    "        if i % TARGET_UPDATE == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            print('Run {} done'.format(i))\n",
    "            torch.save(target_net.state_dict(), 'dqn_models/{}'.format(name))\n",
    "\n",
    "    torch.save(target_net.state_dict(), 'dqn_models/{}'.format(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "f0ee87f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 done\n",
      "Run 10000 done\n",
      "Run 20000 done\n",
      "Run 30000 done\n",
      "Run 40000 done\n",
      "Run 50000 done\n",
      "Run 60000 done\n",
      "Run 70000 done\n",
      "Run 80000 done\n",
      "Run 90000 done\n",
      "Run 100000 done\n",
      "Run 110000 done\n",
      "Run 120000 done\n",
      "Run 130000 done\n",
      "Run 140000 done\n",
      "Run 150000 done\n",
      "Run 160000 done\n",
      "Run 170000 done\n",
      "Run 180000 done\n",
      "Run 190000 done\n",
      "Run 200000 done\n",
      "Run 210000 done\n",
      "Run 220000 done\n",
      "Run 230000 done\n",
      "Run 240000 done\n",
      "Run 250000 done\n",
      "Run 260000 done\n",
      "Run 270000 done\n",
      "Run 280000 done\n",
      "Run 290000 done\n",
      "Run 300000 done\n",
      "Run 310000 done\n",
      "Run 320000 done\n",
      "Run 330000 done\n",
      "Run 340000 done\n",
      "Run 350000 done\n",
      "Run 360000 done\n",
      "Run 370000 done\n",
      "Run 380000 done\n",
      "Run 390000 done\n",
      "Run 400000 done\n",
      "Run 410000 done\n",
      "Run 420000 done\n",
      "Run 430000 done\n",
      "Run 440000 done\n",
      "Run 450000 done\n",
      "Run 460000 done\n",
      "Run 470000 done\n",
      "Run 480000 done\n",
      "Run 490000 done\n",
      "Run 500000 done\n",
      "Run 510000 done\n",
      "Run 520000 done\n",
      "Run 530000 done\n",
      "Run 540000 done\n",
      "Run 550000 done\n",
      "Run 560000 done\n",
      "Run 570000 done\n",
      "Run 580000 done\n",
      "Run 590000 done\n",
      "Run 600000 done\n",
      "Run 610000 done\n",
      "Run 620000 done\n",
      "Run 630000 done\n",
      "Run 640000 done\n",
      "Run 650000 done\n",
      "Run 660000 done\n",
      "Run 670000 done\n",
      "Run 680000 done\n",
      "Run 690000 done\n",
      "Run 700000 done\n",
      "Run 710000 done\n",
      "Run 720000 done\n",
      "Run 730000 done\n",
      "Run 740000 done\n",
      "Run 750000 done\n",
      "Run 760000 done\n",
      "Run 770000 done\n",
      "Run 780000 done\n",
      "Run 790000 done\n",
      "Run 800000 done\n",
      "Run 810000 done\n",
      "Run 820000 done\n",
      "Run 830000 done\n",
      "Run 840000 done\n",
      "Run 850000 done\n",
      "Run 860000 done\n",
      "Run 870000 done\n",
      "Run 880000 done\n",
      "Run 890000 done\n",
      "Run 900000 done\n",
      "Run 910000 done\n",
      "Run 920000 done\n",
      "Run 930000 done\n",
      "Run 940000 done\n",
      "Run 950000 done\n",
      "Run 960000 done\n",
      "Run 970000 done\n",
      "Run 980000 done\n",
      "Run 990000 done\n"
     ]
    }
   ],
   "source": [
    "train(1000000, 'gen_8.0_1mruns.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff0766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2cabb87546583d089e0e7dc4e55b4bf60825fbd1f801f1fd57617645dbbf57f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
