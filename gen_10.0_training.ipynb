{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_rl import create_action_value_dict, create_value_action_dict, create_state, available_moves\n",
    "from player import Player\n",
    "from hand import YatzyHand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dict = create_value_action_dict(Player())\n",
    "action_dict = create_action_value_dict(value_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "with open('300data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for key, value in data.items():\n",
    "    state = re.findall(f'\\d+', key)\n",
    "    state = [float(x) for x in state]\n",
    "    state = torch.tensor(state, device=device)\n",
    "    inputs.append(state)\n",
    "\n",
    "    move = action_dict[value]\n",
    "    outputs.append(torch.tensor(move, device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.stack(inputs)\n",
    "output_tensor = torch.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.layer1 = nn.Linear(20, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 46)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.softmax(self.layer3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Model()\n",
    "    opt = optim.SGD(model.parameters(), lr = lr)\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalGame():\n",
    "    def __init__(self, player, num):\n",
    "        self.player = player\n",
    "        self.scores = []\n",
    "        self.num = num\n",
    "\n",
    "    def get_indices(self, action):\n",
    "        temp = re.findall(f'\\d', value_dict[action])\n",
    "        return [int(x) for x in temp]\n",
    "\n",
    "    \n",
    "    def evaluate(self):\n",
    "        player = self.player\n",
    "\n",
    "        for i in range(self.num):\n",
    "            player.reset_scoresheet()\n",
    "\n",
    "            turns = 0\n",
    "            while turns < 15:\n",
    "                self.turn(player)\n",
    "                turns += 1\n",
    "            \n",
    "            score = player.calculate_score()\n",
    "            self.scores.append(score)\n",
    "\n",
    "    def turn(self, player):\n",
    "        hand = YatzyHand()\n",
    "\n",
    "        rerolls = 0\n",
    "        while rerolls < 2:\n",
    "\n",
    "            move = player.choose_move(hand, reroll=True)\n",
    "\n",
    "            if move >= 15:\n",
    "                rerolls += 1\n",
    "                indices = self.get_indices(move)\n",
    "\n",
    "                hand = hand.reroll(indices)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        move = player.choose_move(hand, reroll=False)\n",
    "\n",
    "        action = value_dict[move]\n",
    "\n",
    "        score = getattr(hand, action)()\n",
    "\n",
    "        player.update_scoresheet(action, score)\n",
    "        \n",
    "    def results(self):\n",
    "        return sum(self.scores) / len(self.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalBot(Player):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Model()\n",
    "    \n",
    "    def load(self, state_dict):\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n",
    "        \n",
    "    def available_moves(self, reroll=False):\n",
    "        final = []\n",
    "        i = 0\n",
    "        for key, value in self.scoresheet.items():\n",
    "            if value == None:\n",
    "                final.append(i)\n",
    "            i += 1\n",
    "        \n",
    "        if reroll:\n",
    "            for i in range(15, 46):\n",
    "                final.append(i)\n",
    "                i += 1\n",
    "                \n",
    "        return torch.tensor(final)\n",
    "\n",
    "\n",
    "    \n",
    "    def choose_move(self, hand, reroll=False):\n",
    "        state = create_state(self.scoresheet, hand)\n",
    "        options = self.available_moves(reroll=reroll)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            available_mask = torch.tensor(tuple(map(lambda x: x not in options, range(46))), device=device, dtype=torch.bool)\n",
    "            \n",
    "            results = model(state)\n",
    "            results[available_mask] = 0\n",
    "            \n",
    "            return torch.argmax(results).view(1).item()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(num, state_dict):\n",
    "    # evaluates a model by having it play num games; pass in the state_dicts\n",
    "    #returns the average score over those games\n",
    "    \n",
    "    player = EvalBot()\n",
    "    player.load(state_dict)\n",
    "\n",
    "    game = EvalGame(player, num)\n",
    "\n",
    "    game.evaluate()\n",
    "\n",
    "    return game.results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "\n",
    "    start_avg = evaluate(100, model.state_dict())\n",
    "    print('Starting average: {}'.format(start_avg))\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        for x, y in train_dl:\n",
    "            preds = model(x)\n",
    "            loss = loss_fn(preds, y)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        print('Epoch {} done'.format(i))\n",
    "        avg = evaluate(100, model.state_dict())\n",
    "        print('Average score: {}'.format(avg))\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting average: 72.53\n",
      "Epoch 0 done\n",
      "Average score: 65.65\n",
      "Epoch 1 done\n",
      "Average score: 56.36\n",
      "Epoch 2 done\n",
      "Average score: 59.15\n",
      "Epoch 3 done\n",
      "Average score: 57.84\n",
      "Epoch 4 done\n",
      "Average score: 67.04\n",
      "Epoch 5 done\n",
      "Average score: 66.61\n",
      "Epoch 6 done\n",
      "Average score: 69.69\n",
      "Epoch 7 done\n",
      "Average score: 68.42\n",
      "Epoch 8 done\n",
      "Average score: 71.07\n",
      "Epoch 9 done\n",
      "Average score: 70.77\n",
      "Epoch 10 done\n",
      "Average score: 67.18\n",
      "Epoch 11 done\n",
      "Average score: 71.57\n",
      "Epoch 12 done\n",
      "Average score: 72.49\n",
      "Epoch 13 done\n",
      "Average score: 69.09\n",
      "Epoch 14 done\n",
      "Average score: 72.91\n",
      "Epoch 15 done\n",
      "Average score: 72.2\n",
      "Epoch 16 done\n",
      "Average score: 71.76\n",
      "Epoch 17 done\n",
      "Average score: 72.31\n",
      "Epoch 18 done\n",
      "Average score: 70.23\n",
      "Epoch 19 done\n",
      "Average score: 76.35\n",
      "Epoch 20 done\n",
      "Average score: 72.9\n",
      "Epoch 21 done\n",
      "Average score: 72.52\n",
      "Epoch 22 done\n",
      "Average score: 72.14\n",
      "Epoch 23 done\n",
      "Average score: 71.3\n",
      "Epoch 24 done\n",
      "Average score: 69.65\n",
      "Epoch 25 done\n",
      "Average score: 75.92\n",
      "Epoch 26 done\n",
      "Average score: 70.6\n",
      "Epoch 27 done\n",
      "Average score: 68.93\n",
      "Epoch 28 done\n",
      "Average score: 76.14\n",
      "Epoch 29 done\n",
      "Average score: 72.58\n",
      "Epoch 30 done\n",
      "Average score: 77.28\n",
      "Epoch 31 done\n",
      "Average score: 75.08\n",
      "Epoch 32 done\n",
      "Average score: 77.9\n",
      "Epoch 33 done\n",
      "Average score: 77.06\n",
      "Epoch 34 done\n",
      "Average score: 80.56\n",
      "Epoch 35 done\n",
      "Average score: 75.48\n",
      "Epoch 36 done\n",
      "Average score: 76.83\n",
      "Epoch 37 done\n",
      "Average score: 76.57\n",
      "Epoch 38 done\n",
      "Average score: 78.05\n",
      "Epoch 39 done\n",
      "Average score: 75.77\n",
      "Epoch 40 done\n",
      "Average score: 70.1\n",
      "Epoch 41 done\n",
      "Average score: 76.8\n",
      "Epoch 42 done\n",
      "Average score: 73.43\n",
      "Epoch 43 done\n",
      "Average score: 72.39\n",
      "Epoch 44 done\n",
      "Average score: 71.61\n",
      "Epoch 45 done\n",
      "Average score: 73.29\n",
      "Epoch 46 done\n",
      "Average score: 74.64\n",
      "Epoch 47 done\n",
      "Average score: 71.62\n",
      "Epoch 48 done\n",
      "Average score: 74.23\n",
      "Epoch 49 done\n",
      "Average score: 74.0\n",
      "Epoch 50 done\n",
      "Average score: 71.18\n",
      "Epoch 51 done\n",
      "Average score: 76.25\n",
      "Epoch 52 done\n",
      "Average score: 72.35\n",
      "Epoch 53 done\n",
      "Average score: 74.62\n",
      "Epoch 54 done\n",
      "Average score: 73.84\n",
      "Epoch 55 done\n",
      "Average score: 73.51\n",
      "Epoch 56 done\n",
      "Average score: 73.2\n",
      "Epoch 57 done\n",
      "Average score: 70.92\n",
      "Epoch 58 done\n",
      "Average score: 77.77\n",
      "Epoch 59 done\n",
      "Average score: 74.08\n",
      "Epoch 60 done\n",
      "Average score: 74.29\n",
      "Epoch 61 done\n",
      "Average score: 77.58\n",
      "Epoch 62 done\n",
      "Average score: 75.45\n",
      "Epoch 63 done\n",
      "Average score: 74.24\n",
      "Epoch 64 done\n",
      "Average score: 70.31\n",
      "Epoch 65 done\n",
      "Average score: 76.1\n",
      "Epoch 66 done\n",
      "Average score: 71.87\n",
      "Epoch 67 done\n",
      "Average score: 74.61\n",
      "Epoch 68 done\n",
      "Average score: 72.33\n",
      "Epoch 69 done\n",
      "Average score: 74.56\n",
      "Epoch 70 done\n",
      "Average score: 78.51\n",
      "Epoch 71 done\n",
      "Average score: 76.73\n",
      "Epoch 72 done\n",
      "Average score: 75.96\n",
      "Epoch 73 done\n",
      "Average score: 75.27\n",
      "Epoch 74 done\n",
      "Average score: 72.46\n",
      "Epoch 75 done\n",
      "Average score: 74.39\n",
      "Epoch 76 done\n",
      "Average score: 74.13\n",
      "Epoch 77 done\n",
      "Average score: 71.35\n",
      "Epoch 78 done\n",
      "Average score: 69.59\n",
      "Epoch 79 done\n",
      "Average score: 75.15\n",
      "Epoch 80 done\n",
      "Average score: 71.82\n",
      "Epoch 81 done\n",
      "Average score: 71.47\n",
      "Epoch 82 done\n",
      "Average score: 72.68\n",
      "Epoch 83 done\n",
      "Average score: 75.17\n",
      "Epoch 84 done\n",
      "Average score: 72.16\n",
      "Epoch 85 done\n",
      "Average score: 73.18\n",
      "Epoch 86 done\n",
      "Average score: 72.41\n",
      "Epoch 87 done\n",
      "Average score: 69.9\n",
      "Epoch 88 done\n",
      "Average score: 70.45\n",
      "Epoch 89 done\n",
      "Average score: 69.27\n",
      "Epoch 90 done\n",
      "Average score: 69.04\n",
      "Epoch 91 done\n",
      "Average score: 69.22\n",
      "Epoch 92 done\n",
      "Average score: 70.27\n",
      "Epoch 93 done\n",
      "Average score: 68.38\n",
      "Epoch 94 done\n",
      "Average score: 70.26\n",
      "Epoch 95 done\n",
      "Average score: 66.76\n",
      "Epoch 96 done\n",
      "Average score: 72.19\n",
      "Epoch 97 done\n",
      "Average score: 69.72\n",
      "Epoch 98 done\n",
      "Average score: 65.73\n",
      "Epoch 99 done\n",
      "Average score: 63.5\n"
     ]
    }
   ],
   "source": [
    "train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2cabb87546583d089e0e7dc4e55b4bf60825fbd1f801f1fd57617645dbbf57f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
